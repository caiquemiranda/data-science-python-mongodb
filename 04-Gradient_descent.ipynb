{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão de Python Neste Jupyter Notebook:', python_version())\n",
    "\n",
    "# usaremos o filtro 'warning' para deixar mais limpo.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Function Minimization (and Maximization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt, numpy as np\n",
    "\n",
    "def f(x):    \n",
    "    return x**4 - 3 * x**3 + 2\n",
    "\n",
    "def df(x):    \n",
    "    return 4 * x**3 - 9 * x**2\n",
    "\n",
    "if __name__ == \"__main__\":    \n",
    "    x = np.arange(-5, 5, 0.2) \n",
    "    y, y_dx = f(x), df(x) \n",
    "    f, axarr = plt.subplots(3, sharex=True)\n",
    "\n",
    "    axarr[0].plot(x, y, color='mediumspringgreen') \n",
    "    axarr[0].set_xlabel('x') \n",
    "    axarr[0].set_ylabel('f(x)') \n",
    "    axarr[0].set_title('f(x)')   \n",
    "    \n",
    "    axarr[1].plot(x, y_dx, color='coral') \n",
    "    axarr[1].set_xlabel('x')  \n",
    "    axarr[1].set_ylabel('dy/dx(x)')   \n",
    "    axarr[1].set_title('derivative of f(x)')   \n",
    "    \n",
    "    axarr[2].set_xlabel('x') \n",
    "    axarr[2].set_ylabel('GD')\n",
    "    axarr[2].set_title('local minimum') \n",
    "\n",
    "    iterations, cur_x, gamma, precision = 0, 6, 0.01, 0.00001  \n",
    "    previous_step_size = cur_x \n",
    "\n",
    "    while previous_step_size > precision: \n",
    "        prev_x = cur_x   \n",
    "        cur_x += -gamma * df(prev_x)   \n",
    "        previous_step_size = abs(cur_x - prev_x)     \n",
    "        iterations += 1 \n",
    "        axarr[2].plot(prev_x, cur_x, \"o\")  \n",
    "        f.subplots_adjust(hspace=0.3)\n",
    "        f.tight_layout()   \n",
    "        plt.show()  \n",
    "        print ('minimum:', cur_x, '\\niterations:', iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt, numpy as np\n",
    "\n",
    "def f(x):   \n",
    "    return x**3 - 6 * x**2 + 9 * x + 15\n",
    "\n",
    "def df(x):   \n",
    "    return 3 * x**2 - 12 * x + 9\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    x = np.arange(-0.5, 5, 0.2) \n",
    "    y = f(x)    plt.figure('f(x)')\n",
    "    \n",
    "    plt.xlabel('x') \n",
    "    plt.ylabel('f(x)')   \n",
    "    plt.title('f(x)')\n",
    "    plt.plot(x, y, color='blueviolet')    \n",
    "    plt.figure('local minimum') \n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('GD')\n",
    "    plt.title('local minimum') \n",
    "    \n",
    "    iterations, cur_x, gamma, precision = 0, 6, 0.01, 0.00001   \n",
    "    previous_step_size = cur_x   \n",
    "    \n",
    "    while previous_step_size > precision:    \n",
    "        prev_x = cur_x       \n",
    "        cur_x += -gamma * df(prev_x)  \n",
    "        previous_step_size = abs(cur_x - prev_x)     \n",
    "        iterations += 1   \n",
    "        plt.plot(prev_x, cur_x, \"o\") \n",
    "        \n",
    "        local_min = cur_x \n",
    "        print ('minimum:', local_min, 'iterations:', iterations)   \n",
    "        \n",
    "        plt.figure('local maximum') \n",
    "        plt.xlabel('x')   \n",
    "        plt.ylabel('GD') \n",
    "        plt.title('local maximum')  \n",
    "        \n",
    "        iterations, cur_x, gamma, precision = 0, 0.5, 0.01, 0.00001  \n",
    "        previous_step_size = cur_x\n",
    "        \n",
    "    while previous_step_size > precision:\n",
    "        prev_x = cur_x   \n",
    "        cur_x += -gamma * -df(prev_x)   \n",
    "        previous_step_size = abs(cur_x - prev_x)    \n",
    "        iterations += 1    \n",
    "        plt.plot(prev_x, cur_x, \"o\")   \n",
    "        \n",
    "        local_max = cur_x   \n",
    "        print ('maximum:', local_max, 'iterations:', iterations)   \n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Distance Minimization Controlling for Step Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random, numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def step(v, direction, step_size): \n",
    "    return [v_i + step_size * direction_i            for v_i, direction_i in zip(v, direction)]\n",
    "\n",
    "def sigmoid_gradient(v):  \n",
    "    return [v_i * (1-v_i) for v_i in v]\n",
    "\n",
    "def mod_vector(v):   \n",
    "    for i, v_i in enumerate(v):\n",
    "    \n",
    "        if v_i == float(\"inf\") or v_i == float(\"-inf\"):\n",
    "            v[i] = random.randint(-1, 1)   \n",
    "    \n",
    "    return v\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    v = [random.randint(-10, 10) for i in range(3)]\n",
    "    tolerance = 0.0000001\n",
    "    iterations = 1  \n",
    "    fig = plt.figure('Euclidean')  \n",
    "    ax = fig.add_subplot(111, projection='3d')  \n",
    "    while True:  \n",
    "        gradient = sigmoid_gradient(v)    \n",
    "        next_v = step(v, gradient, -0.01)    \n",
    "        \n",
    "        xs = gradient[0]\n",
    "        ys = gradient[1]  \n",
    "        zs = gradient[2]   \n",
    "        \n",
    "        ax.scatter(xs, ys, zs, c='lime', marker='o')\n",
    "        v = mod_vector(v)    \n",
    "        next_v = mod_vector(next_v)  \n",
    "        test_v = distance.euclidean(v, next_v) \n",
    "\n",
    "        if test_v < tolerance:   \n",
    "            break        \n",
    "        v = next_v   \n",
    "        iterations += 1 \n",
    "\n",
    "    print ('minimum:', test_v, '\\niterations:', iterations)   \n",
    "    ax.set_xlabel('X axis')\n",
    "    ax.set_ylabel('Y axis')  \n",
    "    ax.set_zlabel('Z axis') \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stabilizing Euclidean Distance Minimization with Monte Carlo Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def step(v, direction, step_size):\n",
    "    return [v_i + step_size * direction_i \n",
    "            for v_i, direction_i in zip(v, direction)]\n",
    "    \n",
    "def sigmoid_gradient(v):   \n",
    "    return [v_i * (1-v_i) for v_i in v]\n",
    "\n",
    "def mod_vector(v):\n",
    "    for i, v_i in enumerate(v):\n",
    "        if v_i == float(\"inf\") or v_i == float(\"-inf\"):\n",
    "            v[i] = random.randint(-1, 1)\n",
    "    return v\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    trials= 10   \n",
    "    sims = 10  \n",
    "    avg_its = []   \n",
    "    for _ in range(trials):   \n",
    "        its = [] \n",
    "        for _ in range(sims):   \n",
    "            v = [random.randint(-10, 10) for i in range(3)] \n",
    "            tolerance = 0.0000001 \n",
    "            iterations = 0     \n",
    "            while True: \n",
    "                gradient = sigmoid_gradient(v)  \n",
    "                next_v = step(v, gradient, -0.01)    \n",
    "                v = mod_vector(v)\n",
    "                next_v = mod_vector(next_v) \n",
    "                test_v = distance.euclidean(v, next_v) \n",
    "                \n",
    "                if test_v < tolerance:\n",
    "                    break\n",
    "                \n",
    "                v = next_v   \n",
    "                iterations += 1\n",
    "            its.append(iterations) \n",
    "        a = round(np.mean(its))\n",
    "        avg_its.append(a) \n",
    "    gap = np.max(avg_its) - np.min(avg_its)   \n",
    "    print (trials, 'trials with', sims, 'simulations each:')   \n",
    "    print ('gap', gap)  \n",
    "    print ('avg iterations', round(np.mean(avg_its)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substituting a NumPy Method to Hasten Euclidean Distance Minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random, numpy as np\n",
    "\n",
    "def step(v, direction, step_size):\n",
    "    return [v_i + step_size * direction_i   \n",
    "            for v_i, direction_i in zip(v, direction)]\n",
    "\n",
    "def sigmoid_gradient(v):\n",
    "    return [v_i * (1-v_i) for v_i in v]\n",
    "\n",
    "def round_v(v):    \n",
    "    return np.round(v, decimals=3)\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    v = [random.randint(-10, 10) for i in range(3)]    \n",
    "    tolerance = 0.0000001   \n",
    "    iterations = 1   \n",
    "    fig = plt.figure('norm')  \n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    while True:   \n",
    "        gradient = sigmoid_gradient(v) \n",
    "        next_v = step(v, gradient, -0.01)      \n",
    "        round_gradient = round_v(gradient)\n",
    "        \n",
    "        xs = round_gradient[0]   \n",
    "        ys = round_gradient[1]\n",
    "        zs = round_gradient[2] \n",
    "        \n",
    "        ax.scatter(xs, ys, zs, c='lime', marker='o')\n",
    "        norm_v = np.linalg.norm(v)\n",
    "        norm_next_v = np.linalg.norm(next_v)\n",
    "        test_v = norm_v - norm_next_v   \n",
    "    \n",
    "        if test_v < tolerance:  \n",
    "            break \n",
    "    \n",
    "        v = next_v  \n",
    "        iterations += 1 \n",
    "    \n",
    "    print ('minimum:', test_v, '\\niterations:', iterations)\n",
    "    \n",
    "    ax.set_xlabel('X axis')\n",
    "    ax.set_ylabel('Y axis')   \n",
    "    ax.set_zlabel('Z axis')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, numpy as np\n",
    "\n",
    "def step(v, direction, step_size):\n",
    "    return [v_i + step_size * direction_i\n",
    "            for v_i, direction_i in zip(v, direction)]\n",
    "\n",
    "def sigmoid_gradient(v):  \n",
    "    return [v_i * (1-v_i) for v_i in v]\n",
    "\n",
    "def round_v(v):\n",
    "    return np.round(v, decimals=3)\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    trials = 10    \n",
    "    sims = 10\n",
    "    avg_its = []  \n",
    "    for _ in range(trials):\n",
    "        its = []    \n",
    "        for _ in range(sims):  \n",
    "            v = [random.randint(-10, 10) for i in range(3)] \n",
    "            tolerance = 0.0000001 \n",
    "            iterations = 0     \n",
    "            while True:  \n",
    "                gradient = sigmoid_gradient(v)\n",
    "                next_v = step(v, gradient, -0.01)\n",
    "                norm_v = np.linalg.norm(v) \n",
    "                norm_next_v = np.linalg.norm(next_v)\n",
    "                test_v = norm_v - norm_next_v   \n",
    "                \n",
    "                if test_v < tolerance:  \n",
    "                    break  \n",
    "                \n",
    "                v = next_v  \n",
    "                iterations += 1      \n",
    "            its.append(iterations)\n",
    "        a = round(np.mean(its))\n",
    "        avg_its.append(a) \n",
    "    gap = np.max(avg_its) - np.min(avg_its)  \n",
    "    print (trials, 'trials with', sims, 'simulations each:') \n",
    "    print ('gap', gap)\n",
    "    print ('avg iterations', round(np.mean(avg_its)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Minimization and Maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random, numpy as np\n",
    "\n",
    "def rnd():    \n",
    "        return [random.randint(-10,10) for i in range(3)]\n",
    "\n",
    "def random_vectors(n): \n",
    "        ls = []   \n",
    "        for v in range(n): \n",
    "                ls.append(rnd())  \n",
    "\n",
    "        return ls\n",
    "        \n",
    "def sos(v):\n",
    "        return sum(v_i ** 2 for v_i in v)\n",
    "\n",
    "def sos_gradient(v):    \n",
    "        return [2 * v_i for v_i in v]\n",
    "\n",
    "def in_random_order(data):   \n",
    "        indexes = [i for i, _ in enumerate(data)]\n",
    "        random.shuffle(indexes)   \n",
    "        for i in indexes:\n",
    "                yield data[i]\n",
    "\n",
    "if __name__ == \"__main__\":   \n",
    "        \n",
    "        v, x, y = rnd(), random_vectors(3), random_vectors(3) \n",
    "        data = list(zip(x, y)) \n",
    "        theta = v    \n",
    "        alpha, value = 0.01, 0 \n",
    "        min_theta, min_value = None, float(\"inf\")    \n",
    "        iterations_with_no_improvement = 0  \n",
    "        n, x = 30, 1 \n",
    "        for i, _ in enumerate(range(n)):\n",
    "                y = np.linalg.norm(theta)\n",
    "                plt.scatter(x, y, c='r')  \n",
    "                x = x + 1  \n",
    "                s = []     \n",
    "                for x_i, y_i in data:  \n",
    "                        s.extend([sos(theta), sos(x_i), sos(y_i)])   \n",
    "                \n",
    "                value = sum(s)\n",
    "                \n",
    "                if value < min_value:  \n",
    "                        min_theta, min_value = theta, value  \n",
    "                        iterations_with_no_improvement = 0      \n",
    "                        alpha = 0.01   \n",
    "                else:\n",
    "                        iterations_with_no_improvement += 1 \n",
    "                        alpha *= 0.9  \n",
    "                \n",
    "                g = []\n",
    "                for x_i, y_i in in_random_order(data):\n",
    "                        g.extend([sos_gradient(theta), sos_gradient(x_i),       \n",
    "                                  sos_gradient(y_i)]) \n",
    "                        for v in g:   \n",
    "                                theta = np.around(np.subtract(theta,alpha*np.array(v)),3)  \n",
    "                                g = []\n",
    "                \n",
    "                print ('minimum:', np.around(min_theta, 4), \n",
    "                       'with', i+1, 'iterations') \n",
    "                \n",
    "                print ('iterations with no improvement:',\n",
    "                       iterations_with_no_improvement)\n",
    "                 \n",
    "                print ('magnitude of min vector:', np.linalg.norm(min_theta))   \n",
    "                \n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random, numpy as np\n",
    "\n",
    "def rnd(): \n",
    "    return [random.randint(-10,10) for i in range(3)]\n",
    "\n",
    "def random_vectors(n): \n",
    "    ls = []  \n",
    "    for v in range(n):\n",
    "        ls.append([random.randint(-10,10) for i in range(3)])\n",
    "    \n",
    "    return ls\n",
    "\n",
    "def sos(v): \n",
    "    return sum(v_i ** 2 for v_i in v)\n",
    "\n",
    "def sos_gradient(v):\n",
    "    return [2 * v_i for v_i in v]\n",
    "\n",
    "def in_random_order(data):   \n",
    "    indexes = [i for i, _ in enumerate(data)]\n",
    "    random.shuffle(indexes)  \n",
    "    for i in indexes:\n",
    "        yield data[i]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    v, x, y = rnd(), random_vectors(3), random_vectors(3)  \n",
    "    data = list(zip(x, y))  \n",
    "    theta = v    \n",
    "    alpha, value = 0.01, 0 \n",
    "    min_theta, min_value = None, float(\"inf\")  \n",
    "    iterations_with_no_improvement = 0    \n",
    "    n, x = 60, 1\n",
    "    for i, _ in enumerate(range(n)):   \n",
    "        y = np.linalg.norm(theta)    \n",
    "        plt.scatter(x, y, c='r')   \n",
    "        x = x + 1  \n",
    "        s = []     \n",
    "        \n",
    "        for x_i, y_i in data:   \n",
    "            s.extend([sos(theta), sos(x_i), sos(y_i)])\n",
    "        \n",
    "        value = sum(s)\n",
    "        if value < min_value:   \n",
    "            min_theta, min_value = theta, value  \n",
    "            iterations_with_no_improvement = 0\n",
    "            alpha = 0.01 \n",
    "        else:\n",
    "            iterations_with_no_improvement += 1 \n",
    "            alpha *= 0.9    \n",
    "            g, t, m = [], [], [] \n",
    "            for x_i, y_i in in_random_order(data):\n",
    "                g.extend([sos_gradient(theta), sos_gradient(x_i),  \n",
    "                          sos_gradient(y_i)])  \n",
    "                \n",
    "                m = np.around([np.linalg.norm(x) for x in g], 2) \n",
    "                for v in g: \n",
    "                    theta = np.around(np.subtract(theta,alpha*np.array(v)),3) \n",
    "                    t.append(np.around(theta,2)) \n",
    "                \n",
    "                mm = np.argmin(m)  \n",
    "                theta = t[mm]\n",
    "                g, m, t = [], [], [] \n",
    "                \n",
    "            print ('minimum:', np.around(min_theta, 4),\n",
    "                   'with', i+1, 'iterations')\n",
    "            \n",
    "            print ('iterations with no improvement:', \n",
    "                   iterations_with_no_improvement)\n",
    "             \n",
    "            print ('magnitude of min vector:', np.linalg.norm(min_theta))    \n",
    "            \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random, numpy as np\n",
    "\n",
    "def rnd():  \n",
    "    return [random.randint(-10,10) for i in range(3)]\n",
    "\n",
    "def random_vectors(n):\n",
    "    ls = []\n",
    "      \n",
    "    for v in range(n): \n",
    "        ls.append([random.randint(-10,10) for i in range(3)])  \n",
    "    return ls\n",
    "\n",
    "def sos_gradient(v):  \n",
    "    return [2 * v_i for v_i in v]\n",
    "\n",
    "def negate(function):\n",
    "    def new_function(*args, **kwargs):  \n",
    "        return np.negative(function(*args, **kwargs))\n",
    "    \n",
    "    return new_function\n",
    "\n",
    "def in_random_order(data):\n",
    "    indexes = [i for i, _ in enumerate(data)]\n",
    "    random.shuffle(indexes) \n",
    "    for i in indexes: \n",
    "        yield data[i]\n",
    "        \n",
    "if __name__ == \"__main__\": \n",
    "    v, x, y = rnd(), random_vectors(3), random_vectors(3) \n",
    "    data = list(zip(x, y)) \n",
    "    theta, alpha = v, 0.01  \n",
    "    neg_gradient = negate(sos_gradient)   \n",
    "    n, x = 100, 1\n",
    "    \n",
    "    for i, row in enumerate(range(n)):\n",
    "        y = np.linalg.norm(theta)   \n",
    "        plt.scatter(x, y, c='r')   \n",
    "        x = x + 1    \n",
    "        g = []      \n",
    "        for x_i, y_i in in_random_order(data):\n",
    "            g.extend([neg_gradient(theta), neg_gradient(x_i), \n",
    "                      neg_gradient(y_i)])\n",
    "            for v in g:\n",
    "                theta = np.around(np.subtract(theta,alpha*np.array(v)),3) \n",
    "            g = []  \n",
    "        print ('maximum:', np.around(theta, 4),  \n",
    "               'with', i+1, 'iterations')\n",
    "        \n",
    "        print ('magnitude of max vector:', np.linalg.norm(theta))  \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Caique Miranda\" -gu \"caiquemiranda\" -iv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
